{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T10:29:53.153613Z",
     "start_time": "2024-10-23T10:29:45.215229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "id": "9487baa4cb5dca8d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 07:29:46.809368: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-23 07:29:46.982435: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-23 07:29:47.030535: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-23 07:29:47.353641: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-23 07:29:50.877923: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T10:30:03.063258Z",
     "start_time": "2024-10-23T10:30:03.055261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras\n",
    "from keras import ops"
   ],
   "id": "bee94d312bc1aa22",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import unicodedata, re\n",
    "import tensorrt as trt\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T10:30:16.369504Z",
     "start_time": "2024-10-23T10:30:16.351668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess(tx):\n",
    "    txt = unicodedata.normalize('NFD', str(tx))\n",
    "    txt = ''.join([char for char in txt if not unicodedata.combining(char)])\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(r\"²+\", \"\", txt)\n",
    "    txt = re.sub(r\"/?\\s*ref\\s*\\.?\\s*[a-zA-Z0-9]+\", \"\", txt)\n",
    "    txt = re.sub(r'(\\d)\\s*,\\s*(\\d)', r'\\1.\\2', txt)\n",
    "    txt = re.sub(r'(?<=\\d)(?=\\D)|(?<=\\D)(?=\\d)', ' ', txt)\n",
    "    txt = re.sub(r'(\\d+)(x)(\\d+)', r'\\1 \\2 \\3', txt)\n",
    "\n",
    "    txt = re.sub(r'(x)(mm|cm)', r' \\1 \\2', txt)\n",
    "    txt = re.sub(r'(mm|cm)(x)', r' \\1 \\2', txt)\n",
    "\n",
    "    txt = re.sub(r'[^\\w\\s\\./]', '', txt)\n",
    "\n",
    "    txt = re.findall(r'\\d+|\\w+|[./]', txt)\n",
    "    txt = ' '.join(txt)\n",
    "\n",
    "    return txt"
   ],
   "id": "5e623b5c3bc4f61b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T10:30:23.026602Z",
     "start_time": "2024-10-23T10:30:22.117046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "root_path = \"../../data/\"\n",
    "df_ = pd.read_csv(root_path+\"df_nondim.csv\")\n",
    "df = pd.read_csv(root_path+\"df.csv\")\n",
    "df = pd.concat([df, df_], ignore_index=True)\n",
    "df = df[\n",
    "    df.category.str.contains(\"PISOS >|PORCELANATOS >|REVESTIMENTOS >\", case=False)\n",
    "    & ~df.category.str.contains(\"ACESSÓRIOS PARA PISOS\", case=False)]\n",
    "\n",
    "df_leroy = pd.read_csv(root_path+\"df_piso_leroy.csv\")\n",
    "\n",
    "df = pd.concat([df, df_leroy], ignore_index=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df = df[[\"id\", \"name\", \"price\"]]\n",
    "#df[\"name\"] = df[\"name\"].apply(preprocess)\n",
    "df.drop_duplicates(inplace=True)\n",
    "display(df.head())\n",
    "df.shape"
   ],
   "id": "5ef4d5cc77aca02e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         id                                               name  price\n",
       "0  999348.0  Porcelanato Calacatta Gold 100x100 Acetinado R...  117.9\n",
       "1  999707.0  Piso Esmaltado Parquet Brilhante 46x46 Tipo A ...   27.9\n",
       "2  999100.0  Porcelanato Georgia Bege Cetim Acetinado Retif...   79.9\n",
       "3  999467.0  Porcelanato Esmaltado HD Fior Di Bosco Acetina...   99.9\n",
       "4  999090.0  Porcelanato Travertino Bege Cetim Acetinado Re...   79.9"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>999348.0</td>\n",
       "      <td>Porcelanato Calacatta Gold 100x100 Acetinado R...</td>\n",
       "      <td>117.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>999707.0</td>\n",
       "      <td>Piso Esmaltado Parquet Brilhante 46x46 Tipo A ...</td>\n",
       "      <td>27.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>999100.0</td>\n",
       "      <td>Porcelanato Georgia Bege Cetim Acetinado Retif...</td>\n",
       "      <td>79.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>999467.0</td>\n",
       "      <td>Porcelanato Esmaltado HD Fior Di Bosco Acetina...</td>\n",
       "      <td>99.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>999090.0</td>\n",
       "      <td>Porcelanato Travertino Bege Cetim Acetinado Re...</td>\n",
       "      <td>79.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2541, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T10:31:49.995044Z",
     "start_time": "2024-10-23T10:31:49.984220Z"
    }
   },
   "cell_type": "code",
   "source": "df.name.to_list()[:10]",
   "id": "3c609452f407b9af",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Porcelanato Calacatta Gold 100x100 Acetinado Retificado Tipo A ELIZABETH / REF. 8055757',\n",
       " 'Piso Esmaltado Parquet Brilhante 46x46 Tipo A INCENOR / REF. PSI 67040',\n",
       " 'Porcelanato Georgia Bege Cetim Acetinado Retificado 80x80 Tipo A INCESA / REF. CO0865E1',\n",
       " 'Porcelanato Esmaltado HD Fior Di Bosco Acetinado 101x101 Tipo A ELIZABETH / REF. 8052889',\n",
       " 'Porcelanato Travertino Bege Cetim Acetinado Retificado 80x80 Tipo A INCESA / REF. CO0027E1',\n",
       " 'Porcelanato Capim Dourado 100x100 Acetinado Retificado Tipo A ELIZABETH / REF. 8055779',\n",
       " 'Porcelanato Tenerife Natural Externo Retificado 26x106 Tipo A INCESA / REF. C61845A1',\n",
       " 'Porcelanato Travertino Bege Externo Retificado 80x80 Tipo A INCESA / REF. CO0027X1',\n",
       " 'Porcelanato Calacatta Gold 100x100 Polido Retificado Tipo A ELIZABETH / REF. 8055783',\n",
       " 'Porcelanato Tenerife Natural Cetim Acetinado Retificado 26x106 Tipo A INCESA / REF. C61845N1']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "['Porcelanato Calacatta Gold 100x100 Acetinado Retificado Tipo A ELIZABETH',\n",
    " 'Piso Esmaltado Parquet Brilhante 46x46 Tipo A INCENOR',\n",
    " 'Porcelanato Georgia Bege Cetim Acetinado Retificado 80x80 Tipo A INCESA',\n",
    " 'Porcelanato Esmaltado HD Fior Di Bosco Acetinado 101x101 Tipo A ELIZABETH',\n",
    " 'Porcelanato Travertino Bege Cetim Acetinado Retificado 80x80 Tipo A INCESA',\n",
    " 'Porcelanato Capim Dourado 100x100 Acetinado Retificado Tipo A ELIZABETH',\n",
    " 'Porcelanato Tenerife Natural Externo Retificado 26x106 Tipo A INCESA',\n",
    " 'Porcelanato Travertino Bege Externo Retificado 80x80 Tipo A INCESA',\n",
    " 'Porcelanato Calacatta Gold 100x100 Polido Retificado Tipo A ELIZABETH',\n",
    " 'Porcelanato Tenerife Natural Cetim Acetinado Retificado 26x106 Tipo A INCESA']"
   ],
   "id": "9f1a6eca6f76a5ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T02:45:18.478361Z",
     "start_time": "2024-10-10T02:45:18.116343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "root_path = \"../../data/\"\n",
    "\n",
    "df = pd.read_csv(root_path+\"df.csv\")\n",
    "df = df[[\"name\", \"brand\", \"price\"]]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df_clean = df.copy()\n",
    "df[\"name\"] = df[\"name\"].apply(preprocess)\n",
    "print(df.shape)\n",
    "df.head()"
   ],
   "id": "c9fa1f2df3e410c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10183, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                name     brand  price\n",
       "0  telha ecologica classica fit 200 x 75 cm verme...  ONDULINE   85.9\n",
       "1             pneu 325 aro 8 com 2 lonas leve colson    COLSON   32.9\n",
       "2       caixa para massa de plastico 20 litros dimax  DIMAX BR   24.9\n",
       "3  esquadro em aco 14 polegadas x 35 . 5 cm com c...  DIMAX BR   18.9\n",
       "4  esquadro em aco 12 polegadas x 30 . 4 cm com c...  DIMAX BR   17.9"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>telha ecologica classica fit 200 x 75 cm verme...</td>\n",
       "      <td>ONDULINE</td>\n",
       "      <td>85.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pneu 325 aro 8 com 2 lonas leve colson</td>\n",
       "      <td>COLSON</td>\n",
       "      <td>32.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>caixa para massa de plastico 20 litros dimax</td>\n",
       "      <td>DIMAX BR</td>\n",
       "      <td>24.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>esquadro em aco 14 polegadas x 35 . 5 cm com c...</td>\n",
       "      <td>DIMAX BR</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>esquadro em aco 12 polegadas x 30 . 4 cm com c...</td>\n",
       "      <td>DIMAX BR</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T18:26:09.779839Z",
     "start_time": "2024-10-22T18:26:09.759609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PositionEmbeddingFixedWeights(keras.layers.Layer):\n",
    "    def __init__(self, sequence_length, vocab_size, output_dim, **kwargs):\n",
    "        super(PositionEmbeddingFixedWeights, self).__init__(**kwargs)\n",
    "        word_embedding_matrix = self.position_encoding(vocab_size, output_dim)\n",
    "        position_embedding_matrix = self.position_encoding(sequence_length, output_dim)\n",
    "        \n",
    "        self.word_embedding_layer = layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=output_dim,\n",
    "            weights=[word_embedding_matrix],\n",
    "            trainable=False\n",
    "        )\n",
    "        self.position_embedding_layer = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=output_dim,\n",
    "            weights=[position_embedding_matrix],\n",
    "            trainable=False\n",
    "        )\n",
    "\n",
    "    def position_encoding(self, seq_len, d, n=10000):\n",
    "        P = np.zeros((seq_len, d))\n",
    "        for k in range(seq_len):\n",
    "            for i in np.arange(int(d/2)):\n",
    "                denominator = np.power(n, 2*i/d)\n",
    "                P[k, 2*i] = np.sin(k/denominator)\n",
    "                P[k, 2*i+1] = np.cos(k/denominator)\n",
    "        return P\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        position_indices = tf.range(tf.shape(inputs)[-1])\n",
    "        embedded_words = self.word_embedding_layer(inputs)\n",
    "        embedded_indices = self.position_embedding_layer(position_indices)\n",
    "        return embedded_words + embedded_indices"
   ],
   "id": "292d7b1ec498ac4d",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T18:26:14.810183Z",
     "start_time": "2024-10-22T18:26:14.561576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 32\n",
    "sequence_len = 11\n",
    "txt_multi_vectorization = layers.TextVectorization(\n",
    "    ngrams=None,\n",
    "    output_mode=\"int\",\n",
    "    split=\"whitespace\",\n",
    "    standardize=None,\n",
    "    output_sequence_length=sequence_len\n",
    ")\n",
    "\n",
    "def make_dataset(x):\n",
    "    X, label = x[\"name\"].tolist(), x[\"price\"].tolist()\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, label))\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(lambda x, y: (txt_multi_vectorization(x), y),\n",
    "                          num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.cache()\n",
    "    return dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.188, random_state=42)\n",
    "train, val = train_test_split(train, test_size=0.177, random_state=42)\n",
    "\n",
    "print(f\"train: {train.shape}, test: {test.shape}, val: {val.shape}\")\n",
    "#print(f\"train: {y_train.shape}, test: {y_test.shape}, val: {y_val.shape}\")\n",
    "\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "val.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "txt_multi_vectorization.adapt(train[\"name\"].tolist())\n",
    "\n",
    "train_ds = make_dataset(train)\n",
    "test_ds  = make_dataset(test)\n",
    "vals_ds  = make_dataset(val)"
   ],
   "id": "a760bbb99871b157",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (1697, 3), test: (478, 3), val: (366, 3)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T18:26:28.557418Z",
     "start_time": "2024-10-22T18:26:28.547186Z"
    }
   },
   "cell_type": "code",
   "source": "vocab_size=txt_multi_vectorization.vocabulary_size()",
   "id": "35a4686435a60866",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T18:26:17.539052Z",
     "start_time": "2024-10-22T18:26:17.514562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PositionalEmbedding(keras.layers.Layer):\n",
    "    def __init__(self, seq_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=input_dim,\n",
    "            output_dim=output_dim)\n",
    "        self.posit_encoding = self.attention_position(\n",
    "            seq_length,\n",
    "            output_dim)\n",
    "        \n",
    "    def compute_mask(self, *args, **kwargs):\n",
    "        return self.token_embeddings.compute_mask(*args, **kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        length = ops.shape(x)[-1]\n",
    "        x = self.token_embeddings(x)\n",
    "    \n",
    "        x *= ops.sqrt(ops.cast(self.output_dim, tf.float32))\n",
    "        x += self.posit_encoding[tf.newaxis, :length, :]\n",
    "        return x\n",
    "\n",
    "    def attention_position(self, length, depth):\n",
    "        positions = np.arange(length)[:, np.newaxis]\n",
    "        depth_indices = np.arange(depth)[np.newaxis, :] / depth\n",
    "        angle_rates = 1 / (1e4 ** (depth_indices / 2))\n",
    "        angle_rads = positions * angle_rates\n",
    "    \n",
    "        pos_encoding = np.zeros_like(angle_rads)\n",
    "        pos_encoding[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        pos_encoding[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"input_dim\": self.input_dim,\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"seq_length\": self.seq_length,\n",
    "        })\n",
    "        return config"
   ],
   "id": "26706b6690371788",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T18:26:19.884565Z",
     "start_time": "2024-10-22T18:26:19.858168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, dropout_rate=0.1, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(f\"embed_dim ({embed_dim}) deve ser divisível por num_heads ({num_heads})\")\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Multi-head attention\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=self.num_heads,\n",
    "            key_dim=self.embed_dim,\n",
    "            dropout=self.dropout_rate\n",
    "        )\n",
    "\n",
    "        # Feed-forward network\n",
    "        self.dense_proj = keras.Sequential([\n",
    "            layers.Dense(self.dense_dim, activation=\"relu\"),\n",
    "            layers.Dropout(self.dropout_rate),\n",
    "            layers.Dense(self.embed_dim)\n",
    "        ])\n",
    "\n",
    "        # Layer normalizations\n",
    "        self.layernorm_1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        # Dropout layers\n",
    "        self.dropout1 = layers.Dropout(self.dropout_rate)\n",
    "        self.dropout2 = layers.Dropout(self.dropout_rate)\n",
    "\n",
    "        super(TransformerEncoder, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        # Aplicar layer norm antes da attention (pre-norm)\n",
    "        normalized = self.layernorm_1(inputs)\n",
    "\n",
    "        # Multi-head attention\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
    "        else:\n",
    "            padding_mask = None\n",
    "\n",
    "        attention_output = self.attention(\n",
    "            query=normalized,\n",
    "            value=normalized,\n",
    "            key=normalized,\n",
    "            attention_mask=padding_mask,\n",
    "            training=training\n",
    "        )\n",
    "\n",
    "        # Residual connection e dropout após attention\n",
    "        attention_output = self.dropout1(attention_output, training=training)\n",
    "        out1 = inputs + attention_output\n",
    "\n",
    "        # Feed-forward network com pre-norm\n",
    "        normalized_2 = self.layernorm_2(out1)\n",
    "        ff_output = self.dense_proj(normalized_2)\n",
    "\n",
    "        # Residual connection e dropout após feed-forward\n",
    "        ff_output = self.dropout2(ff_output, training=training)\n",
    "        return out1 + ff_output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "            \"dropout_rate\": self.dropout_rate\n",
    "        })\n",
    "        return config"
   ],
   "id": "b9647aceb004aaa",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T18:26:32.230162Z",
     "start_time": "2024-10-22T18:26:31.016867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embed_dim, dense_dim, num_heads = 256, 512, 8\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "x = PositionalEmbedding(sequence_len, vocab_size, embed_dim)(inputs)\n",
    "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "#x = layers.BatchNormalization()(x)\n",
    "\n",
    "outputs = layers.Dense(1)(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.001,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9\n",
    ")\n",
    "optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=\"mae\",\n",
    "    metrics=[\"r2_score\", \"mean_absolute_percentage_error\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ],
   "id": "c4531daa495d7fb8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001B[38;5;33mInputLayer\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ positional_embedding            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)      │       \u001B[38;5;34m352,256\u001B[0m │\n",
       "│ (\u001B[38;5;33mPositionalEmbedding\u001B[0m)           │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)      │     \u001B[38;5;34m2,367,488\u001B[0m │\n",
       "│ (\u001B[38;5;33mTransformerEncoder\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mGlobalMaxPooling1D\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │           \u001B[38;5;34m257\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ positional_embedding            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">352,256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)           │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,367,488</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m2,720,001\u001B[0m (10.38 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,720,001</span> (10.38 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m2,720,001\u001B[0m (10.38 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,720,001</span> (10.38 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T18:26:41.248109Z",
     "start_time": "2024-10-22T18:26:37.162800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"regressor_model.keras\",\n",
    "                                    save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                  patience=6,\n",
    "                                  restore_best_weights=True)\n",
    "]\n",
    "\n",
    "histories = model.fit(\n",
    "    train_ds,\n",
    "    epochs=30,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=vals_ds,\n",
    ")\n",
    "model_hp = keras.models.load_model(\n",
    "    \"regressor_model.keras\",\n",
    "    custom_objects={\"TransformerEncoder\": TransformerEncoder,\n",
    "                    \"PositionalEmbedding\": PositionalEmbedding})\n",
    "print(f\"MAE: {model_hp.evaluate(test_ds)}\")"
   ],
   "id": "41cf4c4f02b1f80e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1729621600.373796    8154 service.cc:146] XLA service 0x790b38007af0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1729621600.373817    8154 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2024-10-22 15:26:40.457551: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-22 15:26:40.841610: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:536] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\n",
      "2024-10-22 15:26:40.841668: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:540] Memory usage: 5242880 bytes free, 6020661248 bytes total.\n",
      "2024-10-22 15:26:40.841704: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:550] Possibly insufficient driver version: 560.35.3\n",
      "2024-10-22 15:26:41.196536: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:536] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\n",
      "2024-10-22 15:26:41.196586: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:540] Memory usage: 5242880 bytes free, 6020661248 bytes total.\n",
      "2024-10-22 15:26:41.196622: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:550] Possibly insufficient driver version: 560.35.3\n",
      "2024-10-22 15:26:41.206199: W tensorflow/core/framework/op_kernel.cc:1840] OP_REQUIRES failed at xla_ops.cc:577 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2024-10-22 15:26:41.206244: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_8073/775616991.py\", line 9, in <module>\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_one_step_on_iterator_6813]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFailedPreconditionError\u001B[0m                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 9\u001B[0m\n\u001B[1;32m      1\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m      2\u001B[0m     keras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mModelCheckpoint(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mregressor_model.keras\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      3\u001B[0m                                     save_best_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      6\u001B[0m                                   restore_best_weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      7\u001B[0m ]\n\u001B[0;32m----> 9\u001B[0m histories \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_ds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvals_ds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m model_hp \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mmodels\u001B[38;5;241m.\u001B[39mload_model(\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mregressor_model.keras\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     17\u001B[0m     custom_objects\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTransformerEncoder\u001B[39m\u001B[38;5;124m\"\u001B[39m: TransformerEncoder,\n\u001B[1;32m     18\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPositionalEmbedding\u001B[39m\u001B[38;5;124m\"\u001B[39m: PositionalEmbedding})\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMAE: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_hp\u001B[38;5;241m.\u001B[39mevaluate(test_ds)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    124\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[1;32m     54\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mFailedPreconditionError\u001B[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_8073/775616991.py\", line 9, in <module>\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\n\n  File \"/home/laccan/IdeaProjects/Orion/ovenv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_one_step_on_iterator_6813]"
     ]
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
